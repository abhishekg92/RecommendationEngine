{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.mllib.recommendation import ALS\n",
    " \n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "class RecommendationEngine:\n",
    "    \"\"\"A movie recommendation engine\n",
    "    \"\"\"\n",
    " \n",
    "    def __count_and_average_ratings(self):\n",
    "        \"\"\"Updates the movies ratings counts from \n",
    "        the current data self.ratings_RDD\n",
    "        \"\"\"\n",
    "        logger.info(\"Counting movie ratings...\")\n",
    "        movie_ID_with_ratings_RDD = self.ratings_RDD.map(lambda x: (x[1], x[2])).groupByKey()\n",
    "        movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "        self.movies_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))\n",
    " \n",
    " \n",
    "    def __train_model(self):\n",
    "        \"\"\"Train the ALS model with the current dataset\n",
    "        \"\"\"\n",
    "        logger.info(\"Training the ALS model...\")\n",
    "        self.model = ALS.train(self.ratings_RDD, self.rank, seed=self.seed,\n",
    "                               iterations=self.iterations, lambda_=self.regularization_parameter)\n",
    "        logger.info(\"ALS model built!\")\n",
    " \n",
    " \n",
    "    def __init__(self, sc, dataset_path):\n",
    "        \"\"\"Init the recommendation engine given a Spark context and a dataset path\n",
    "        \"\"\"\n",
    " \n",
    "        logger.info(\"Starting up the Recommendation Engine: \")\n",
    " \n",
    "        self.sc = sc\n",
    " \n",
    "        # Load ratings data for later use\n",
    "        logger.info(\"Loading Ratings data...\")\n",
    "        ratings_file_path = os.path.join(dataset_path, 'ratings.dat')\n",
    "        ratings_raw_RDD = self.sc.textFile(ratings_file_path)\n",
    "        ratings_raw_data_header = ratings_raw_RDD.take(1)[0]\n",
    "        self.ratings_RDD = ratings_raw_RDD.filter(lambda line: line!=ratings_raw_data_header)\\\n",
    "            .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "        # Load movies data for later use\n",
    "        logger.info(\"Loading Movies data...\")\n",
    "        movies_file_path = os.path.join(dataset_path, 'movies.dat')\n",
    "        movies_raw_RDD = self.sc.textFile(movies_file_path)\n",
    "        movies_raw_data_header = movies_raw_RDD.take(1)[0]\n",
    "        self.movies_RDD = movies_raw_RDD.filter(lambda line: line!=movies_raw_data_header)\\\n",
    "            .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "        self.movies_titles_RDD = self.movies_RDD.map(lambda x: (int(x[0]),x[1])).cache()\n",
    "        # Pre-calculate movies ratings counts\n",
    "        self.__count_and_average_ratings()\n",
    " \n",
    "        # Train the model\n",
    "        self.rank = 8\n",
    "        self.seed = 5L\n",
    "        self.iterations = 10\n",
    "        self.regularization_parameter = 0.1\n",
    "        self.__train_model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "\n",
    "import os\n",
    "\n",
    "datasets_path = os.path.join('/Users/schakraborty/Documents/', 'datasets')\n",
    "\n",
    "complete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\n",
    "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "small_f = urllib.urlretrieve (small_dataset_url, small_dataset_path)\n",
    "complete_f = urllib.urlretrieve (complete_dataset_url, complete_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)\n",
    "\n",
    "with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
